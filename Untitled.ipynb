{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b426212-5980-465c-8a01-292604151a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 13:51:11.481385: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-14 13:51:11.494285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749909071.507309    8437 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749909071.510703    8437 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749909071.519940    8437 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749909071.519961    8437 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749909071.519962    8437 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749909071.519964    8437 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-14 13:51:11.522792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import  Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input,Dropout,BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94694d8a-caeb-4c70-a3a4-05cef368fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  path = \"/mnt/c/Users/Likhith/Desktop/Sign_Language_Predictor/Indian\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbf8d6b9-be74-4a44-ab84-3721a7255b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 32\n",
    "img_height = 32\n",
    "\n",
    "batch_size = 64\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984fe34c-a681-4b33-802a-c5c70012f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42745 files belonging to 35 classes.\n",
      "Using 34196 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749909555.926453    8437 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3620 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42745 files belonging to 35 classes.\n",
      "Using 8549 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "    dataset,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = seed,\n",
    "    image_size = (img_width, img_height),\n",
    "    batch_size = batch_size\n",
    "\n",
    ")\n",
    "\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    dataset,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = seed,\n",
    "    image_size = (img_width,img_height),\n",
    "    batch_size=batch_size\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921fdfea-07c2-48c0-94f6-bcf2a3c6bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(validation_ds)\n",
    "\n",
    "val_ds = validation_ds.take(val_batches//2)\n",
    "test_ds = validation_ds.take(val_batches//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "579d4da1-b381-4284-b963-fb4ff46cbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "     Input(shape=(32, 32, 3)),\n",
    "     Conv2D(512,(3,3),activation = \"relu\", padding =\"same\",),\n",
    "     BatchNormalization(),\n",
    "     MaxPooling2D(2,2),\n",
    "     Dropout(0.4),\n",
    "     Conv2D(256,(3,3),activation = \"relu\",padding =\"same\"),\n",
    "     BatchNormalization(),\n",
    "     MaxPooling2D(2,2),\n",
    "     Dropout(0.3),\n",
    "     Conv2D(128,(3,3),activation = \"relu\",padding =\"same\"),\n",
    "     BatchNormalization(),\n",
    "     MaxPooling2D(2,2),\n",
    "     Dropout(0.2),\n",
    "     Conv2D(64,(3,3),activation = \"relu\",padding =\"same\"),\n",
    "     BatchNormalization(),\n",
    "     MaxPooling2D(2,2),\n",
    "     Dropout(0.1),\n",
    "      Conv2D(32,(3,3),activation = \"relu\",padding =\"same\"),\n",
    "     BatchNormalization(),\n",
    "     MaxPooling2D(2,2),\n",
    "     Dropout(0.08),\n",
    "     Flatten(),\n",
    "     Dense(512,activation =\"relu\"),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.4),\n",
    "     Dense(256,activation =\"relu\"),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.3),\n",
    "     Dense(128,activation =\"relu\"),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.2),\n",
    "     Dense(64,activation =\"relu\"),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.1),\n",
    "     Dense(35,activation =\"softmax\"),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33ef8263-948b-4e13-b700-61f29f0e8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75614fe6-9fa0-44be-a74e-e570c76a9b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749909633.893494    8569 service.cc:152] XLA service 0x76519800ec80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1749909633.893537    8569 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 6GB Laptop GPU, Compute Capability 8.6\n",
      "2025-06-14 14:00:34.024041: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1749909634.725549    8569 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1749909649.177137    8569 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 78ms/step - accuracy: 0.5748 - loss: 1.7058 - val_accuracy: 0.9907 - val_loss: 0.0235\n",
      "Epoch 2/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 59ms/step - accuracy: 0.9845 - loss: 0.0707 - val_accuracy: 0.9956 - val_loss: 0.0110\n",
      "Epoch 3/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 59ms/step - accuracy: 0.9924 - loss: 0.0322 - val_accuracy: 0.9981 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 58ms/step - accuracy: 0.9956 - loss: 0.0182 - val_accuracy: 0.9991 - val_loss: 0.0032\n",
      "Epoch 5/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 59ms/step - accuracy: 0.9956 - loss: 0.0162 - val_accuracy: 0.9995 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 53ms/step - accuracy: 0.9966 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 2.2836e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 58ms/step - accuracy: 0.9984 - loss: 0.0076 - val_accuracy: 0.9879 - val_loss: 0.0382\n",
      "Epoch 8/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 59ms/step - accuracy: 0.9958 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 59ms/step - accuracy: 0.9950 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 1.3802e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 59ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 2.0569e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = 10,\n",
    "    batch_size = 35\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80f11de5-daa5-4cd5-8d7a-22243f17a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"/mnt/c/Users/Likhith/Desktop/Sign_Language_Predictor/model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e926fd83-ebd6-47a4-96b3-315a62377eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.0488e-05\n",
      "Accuracy 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(test_ds)\n",
    "print(f\"Accuracy {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8227d-19db-4495-9c3a-921381d5d0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
